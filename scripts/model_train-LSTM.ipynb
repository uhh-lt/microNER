{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np \n",
    "from keras.utils import to_categorical\n",
    "from validation import compute_f1\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
    "# from prepro import readfile,createBatches,createMatrices,iterate_minibatches,addCharInformatioin,padding\n",
    "from keras.utils import plot_model,Progbar\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from numpy import newaxis\n",
    "import sklearn\n",
    "import subprocess\n",
    "import fastText\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCasing(word, caseLookup):   \n",
    "    casing = 'other'\n",
    "    \n",
    "    numDigits = 0\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            numDigits += 1\n",
    "            \n",
    "    digitFraction = numDigits / float(len(word))\n",
    "    \n",
    "    if word.isdigit(): #Is a digit\n",
    "        casing = 'numeric'\n",
    "    elif digitFraction > 0.5:\n",
    "        casing = 'mainly_numeric'\n",
    "    elif word.islower(): #All lower case\n",
    "        casing = 'allLower'\n",
    "    elif word.isupper(): #All upper case\n",
    "        casing = 'allUpper'\n",
    "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
    "        casing = 'initialUpper'\n",
    "    elif numDigits > 0:\n",
    "        casing = 'contains_digit'\n",
    "    \n",
    "   \n",
    "    return caseLookup[casing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing all deriv and part to misc. with BIO\n",
    "def modify_labels(dataset):\n",
    "    bad_labels = ['I-PERderiv','I-OTHpart','B-ORGderiv', 'I-OTH','B-OTHpart','B-LOCderiv','I-LOCderiv','I-OTHderiv','B-PERderiv','B-OTHderiv','B-PERpart','I-PERpart','I-LOCpart','B-LOCpart','I-ORGpart','I-ORGderiv','B-ORGpart','B-OTH']\n",
    "    for sentence in dataset:\n",
    "        for word in sentence:\n",
    "            label = word[1]\n",
    "            if label in bad_labels:\n",
    "                first_char = label[0]\n",
    "                if first_char == 'B' :\n",
    "                    word[1] = 'B-MISC'\n",
    "                else:\n",
    "                    word[1] = 'I-MISC'\n",
    "    return dataset\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_germeval(path):\n",
    "    sentences = []\n",
    "    with open(path, 'r', encoding = 'UTF-8') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            \n",
    "            line = line.strip()\n",
    "            \n",
    "            # append sentence\n",
    "            if len(line) == 0:\n",
    "                if len(sentence):\n",
    "                    sentences.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            \n",
    "            # get sentence tokens\n",
    "            splits = line.split()\n",
    "            if splits[0] == '#':\n",
    "                continue\n",
    "            temp = [splits[1],splits[2]]\n",
    "            sentence.append(temp)\n",
    "        \n",
    "        # append last\n",
    "        if len(sentence):\n",
    "            sentences.append(sentence)    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproecessing data from Conll\n",
    "def get_sentences_conll(filename):\n",
    "    '''\n",
    "        -DOCSTART- -X- -X- O\n",
    "\n",
    "    EU NNP B-NP B-ORG\n",
    "    rejects VBZ B-VP O\n",
    "    German JJ B-NP B-MISC\n",
    "    call NN I-NP O\n",
    "    to TO B-VP O\n",
    "    boycott VB I-VP O\n",
    "    British JJ B-NP B-MISC\n",
    "    lamb NN I-NP O\n",
    "    . . O O\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    read file\n",
    "    return format :\n",
    "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
    "    '''\n",
    "    f = open(filename,'rb')\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        splits = line.split()\n",
    "        try:\n",
    "            word=splits[0].decode()\n",
    "            if word=='-DOCSTART-':\n",
    "                continue\n",
    "            label=splits[-1].decode()\n",
    "            temp=[word,label]\n",
    "            sentence.append(temp)\n",
    "        except Exception as e:\n",
    "            if len(sentence)!=0:\n",
    "                sentences.append(sentence)\n",
    "                sentence=[]\n",
    "    return sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = get_sentences('../data/CONLL/deu/deu_utf.train')\n",
    "# devSentences = get_sentences('../data/CONLL/deu/deu_utf.testa')\n",
    "# testSentences = get_sentences('../data/CONLL/deu/deu_utf.testb')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1951', 'O'], ['bis', 'O'], ['1953', 'O'], ['wurde', 'O'], ['der', 'O'], ['nördliche', 'O'], ['Teil', 'O'], ['als', 'O'], ['Jugendburg', 'O'], ['des', 'O'], ['Kolpingwerkes', 'B-OTH'], ['gebaut', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "label2Idx = {}\n",
    "for label in labelSet:\n",
    "    label2Idx[label] = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'I-LOCderiv': 1, 'B-PER': 2, 'B-OTHderiv': 4, 'I-PERderiv': 5, 'B-ORGpart': 3, 'I-PER': 7, 'I-OTHpart': 6, 'I-OTH': 8, 'B-LOC': 9, 'B-ORGderiv': 10, 'I-LOC': 18, 'B-LOCpart': 17, 'I-PERpart': 20, 'B-PERderiv': 11, 'I-OTHderiv': 12, 'B-PERpart': 13, 'I-ORG': 19, 'B-OTHpart': 14, 'B-LOCderiv': 15, 'I-ORGpart': 21, 'I-LOCpart': 24, 'I-ORGderiv': 22, 'B-ORG': 23, 'B-OTH': 16}\n"
     ]
    }
   ],
   "source": [
    "print(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
    "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "{'allLower': 1, 'numeric': 0, 'initialUpper': 3, 'PADDING_TOKEN': 7, 'contains_digit': 6, 'allUpper': 2, 'mainly_numeric': 5, 'other': 4}\n"
     ]
    }
   ],
   "source": [
    "print(caseEmbeddings)\n",
    "print(case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'術': 0, '8': 1, 'オ': 2, '“': 3, 'ş': 219, ':': 4, 'Â': 5, 'έ': 6, 'П': 218, 'ا': 203, '‘': 7, 'ɨ': 8, 'Π': 9, '士': 117, 'д': 10, '柯': 16, '→': 14, '’': 13, 'ن': 15, '太': 17, 'п': 212, '南': 191, 'î': 286, '_': 19, '傳': 21, '-': 169, 'ς': 296, '▪': 22, 'Т': 320, 'ό': 24, 'U': 25, 'ı': 26, '!': 27, 'а': 28, 'e': 29, 'Ş': 38, 'ô': 35, '†': 34, 'æ': 37, 'N': 325, 'ї': 40, 'ğ': 41, 'з': 42, 'υ': 231, 'И': 208, 'ж': 43, 'л': 44, '6': 45, 'L': 47, 'È': 49, 'Ц': 53, '동': 54, '貴': 55, 'ū': 56, 'ī': 58, 'Е': 59, 'y': 60, 'λ': 61, 'Î': 275, 'r': 63, '²': 64, 'ế': 65, '[': 67, 'q': 68, '\\u200e': 70, 'х': 71, '4': 73, '}': 76, 'ν': 282, '博': 249, '別': 77, '3': 234, 'ي': 62, 'أ': 78, 'k': 79, 'Ø': 80, '´': 82, 'O': 83, '§': 72, '守': 85, 'ـ': 86, '9': 88, '½': 91, '¸': 247, 'ħ': 18, '루': 93, 'ä': 12, 'ř': 95, '‹': 97, '算': 99, 'м': 180, 'K': 101, 'í': 103, 'Č': 305, '≘': 75, 'ā': 276, '\\x94': 111, 'a': 108, 'C': 74, '李': 113, 'ŏ': 114, 'x': 115, '鷹': 221, 'ʻ': 183, '造': 116, 'є': 283, '台': 118, 'z': 119, 'h': 120, '±': 121, '«': 122, '»': 123, '(': 124, '”': 189, 'ċ': 125, 'ラ': 126, 'г': 127, '寝': 131, 'F': 129, 'ú': 254, 'У': 132, 'UNKNOWN': 328, 'w': 246, 'Л': 133, 'm': 20, '樓': 134, '°': 135, 'ë': 110, 'ó': 136, '—': 137, '¹': 142, 'ê': 141, 'Ö': 130, 'Æ': 193, 'ο': 143, 'à': 144, '£': 145, '©': 146, 'œ': 250, 'é': 147, 'σ': 148, '$': 149, 'Ġ': 153, ';': 152, 'š': 66, 'ň': 154, 'В': 155, 'у': 159, 'l': 157, '−': 160, 'ệ': 295, ',': 128, 'v': 162, 'ż': 299, '학': 166, 'á': 304, 'ñ': 164, 'å': 165, 'Y': 167, '\"': 168, 'É': 253, 'n': 170, '0': 87, '⊃': 172, 'Q': 173, 'η': 174, 'ḫ': 175, 'ĩ': 176, '›': 84, '‚': 177, 'Λ': 178, 'ι': 314, 'p': 179, 'φ': 181, 'Á': 182, 'ł': 257, 'ъ': 185, 'ě': 186, 'ῦ': 187, 'Ż': 327, 'в': 195, 'и': 188, 'Þ': 138, 'M': 51, '`': 216, '+': 192, 'γ': 140, '冲': 194, 'е': 89, '대': 196, 'Ш': 197, '%': 198, '별': 237, '懿': 200, '\\x95': 199, 'ć': 202, 'ḳ': 204, 'ø': 30, 's': 205, 'o': 278, 'С': 90, 'V': 207, 'τ': 302, '\\x96': 209, '\\x9a': 210, 'ρ': 306, 'À': 290, 'G': 211, 'ž': 201, 'P': 213, '„': 31, 'R': 214, '‐': 215, 'I': 92, '=': 217, \"'\": 32, 'd': 220, 'ю': 310, '\\x99': 184, 'B': 33, 'π': 225, ']': 226, 'я': 227, 'ü': 228, 'u': 229, 'ę': 230, '>': 300, 'W': 94, 'g': 232, 'ö': 233, '~': 235, '€': 313, 'İ': 236, 'ō': 96, 'ť': 39, 'β': 239, '…': 241, '/': 242, '–': 243, 'ß': 244, 'ē': 190, 'й': 11, '妃': 309, 't': 248, '\\xad': 224, 'Å': 251, 'ǒ': 222, 'b': 252, '⋅': 150, 'J': 255, 'ε': 256, 'α': 258, 'ś': 151, 'Œ': 171, 'è': 259, '·': 260, 'č': 261, 'ń': 262, ')': 206, '\\x80': 264, 'S': 102, 'ź': 265, 'ç': 266, 'ă': 319, 'ą': 267, 'µ': 268, '5': 269, 'j': 270, 'T': 271, 'H': 104, 'ψ': 100, 'Ü': 156, '佐': 112, 'ð': 23, '2': 279, 'û': 280, 'р': 281, '章': 317, 'E': 285, '九': 288, 'н': 287, '#': 315, '&': 107, '殿': 106, 'к': 158, 'ő': 289, '*': 109, 'X': 291, '≤': 292, 'Ł': 293, 'Z': 272, 'f': 294, 'т': 273, 'Ä': 297, '?': 298, '鶴': 322, 'ã': 245, 'б': 48, 'с': 301, 'κ': 277, 'ь': 303, '″': 46, 'ы': 98, '7': 324, '×': 307, '@': 274, '<': 308, '.': 161, 'â': 105, '¤': 311, 'c': 139, 'D': 238, 'Ž': 312, 'М': 163, 'i': 57, 'о': 316, '1': 318, '³': 52, 'ض': 69, 'A': 50, 'ņ': 240, 'ب': 321, '東': 81, '公': 323, '\\x92': 36, 'ά': 263, 'Š': 326, 'ý': 284, 'õ': 223}\n"
     ]
    }
   ],
   "source": [
    "char2Idx={}\n",
    "for char in characters:\n",
    "    char2Idx[char] = len(char2Idx)\n",
    "char2Idx['UNKNOWN'] = len(char2Idx)\n",
    "print(char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fastText.load_model(\"../embeddings/wiki.de.bin\")\n",
    "# ft = fastText.load_model(\"../embeddings/cc.de.300.bin\")\n",
    "\n",
    "nb_embedding_dims = ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(dataset):\n",
    "    l = []\n",
    "    for i in dataset:\n",
    "        l.append(len(i))\n",
    "    l = set(l)\n",
    "    print(len(l))\n",
    "    batches = []\n",
    "    batch_len = []\n",
    "    z = 0\n",
    "    for i in l:\n",
    "        temp = []\n",
    "        for batch in dataset:\n",
    "            if len(batch) == i:\n",
    "                temp.append(batch)\n",
    "                z += 1\n",
    "        batches.append(temp)\n",
    "#         batch_len.append(z)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "45\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "train_batches = createBatches(trainSentences)\n",
    "dev_batches = createBatches(devSentences)\n",
    "test_batches = createBatches(testSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "3\n",
      "[[['Alles', 'O'], ['richtig', 'O'], ['.', 'O']], [['Farben', 'O'], ['eingeführt', 'O'], ['.', 'O']], [['Material', 'O'], ['gewinnen', 'O'], ['.', 'O']]]\n"
     ]
    }
   ],
   "source": [
    "batches = train_batches\n",
    "print(len(batches))\n",
    "print(len(batches[0]))\n",
    "print(batches[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_char_embedding_dims = 52\n",
    "\n",
    "def generator(batches: 'list of training/dev sentences- batches already created'):\n",
    "    global line_number\n",
    "    \n",
    "    while True:\n",
    "        for batch in batches:\n",
    "            word_embeddings = []\n",
    "            case_embeddings = []\n",
    "            char_embeddings = []\n",
    "\n",
    "            output_labels = []\n",
    "            for index in range(len(batch)): # batches made according to the size of the sentences. len(batch) gives the size of current batch\n",
    "                sentence = batch[index]\n",
    "    #             print(sentence)\n",
    "                temp_casing = []\n",
    "                temp_char=[]\n",
    "                temp_word=[]\n",
    "                temp_output=[]\n",
    "                for word in sentence:\n",
    "                    word, label = word\n",
    "                    casing =getCasing(word, case2Idx)\n",
    "                    temp_casing.append(casing)\n",
    "                    temp_char2=[]\n",
    "                    for char in word:\n",
    "                        if char in char2Idx.keys():\n",
    "                            temp_char2.append(char2Idx[char])\n",
    "                        else:\n",
    "                            temp_char2.append(char2Idx['UNKNOWN']) # To incorporate the words which are not in the vocab\n",
    "                    temp_char2 = np.array(temp_char2)\n",
    "                    temp_char.append(temp_char2)\n",
    "                    word_vector = ft.get_word_vector(word.lower())\n",
    "                    # word_vector = ft.get_word_vector(word)\n",
    "                    temp_word.append(word_vector)\n",
    "                    temp_output.append(label2Idx[label])\n",
    "                temp_char = pad_sequences(temp_char, nb_char_embedding_dims)\n",
    "                word_embeddings.append(temp_word)\n",
    "                case_embeddings.append(temp_casing)\n",
    "                char_embeddings.append(temp_char)\n",
    "                temp_output = to_categorical(temp_output, 25)\n",
    "                output_labels.append(temp_output)\n",
    "    #             output_labels = to_categorical()\n",
    "    #             output_labels = np.array(output_labels)\n",
    "    #             output_labels = output_labels[...,newaxis]\n",
    "\n",
    "    #             print(np.array(word_embeddings).shape)\n",
    "    #             print(np.array(case_embeddings).shape)\n",
    "    #             print(np.array(char_embeddings).shape)\n",
    "    #             print(output_labels.shape)\n",
    "    #             print(\"******************\\n\\n\")\n",
    "            yield ([np.array(word_embeddings), np.array(case_embeddings), np.array(char_embeddings)], np.array(output_labels))\n",
    "\n",
    "def get_label_from_categorical(a):\n",
    "    labels = []\n",
    "    for label in a:\n",
    "        label = np.ndarray.tolist(label)\n",
    "        label = np.argmax(label)\n",
    "        labels.append(label)\n",
    "    return(labels)\n",
    "\n",
    "def predict_batches(batch):\n",
    "    steps = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for input_data, output_data in generator(batch):\n",
    "        pred_labels_batch = model.predict(input_data)\n",
    "        for s in pred_labels_batch:\n",
    "            pred_labels.append(get_label_from_categorical(s))\n",
    "        for s in output_data:\n",
    "            true_labels.append(get_label_from_categorical(s))\n",
    "        steps += 1\n",
    "        if steps == len(batch):\n",
    "            break\n",
    "    return(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2Label = {v: k for k, v in label2Idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for s in y_pred:\n",
    "        pred_labels.append(get_label_from_categorical(s))\n",
    "    for s in y_true:\n",
    "        true_labels.append(get_label_from_categorical(s))\n",
    "    p, r, f = compute_f1(y_pred, y_true, idx2Label)\n",
    "    return r\n",
    "\n",
    "def get_model():\n",
    "    words_input = Input(shape=(None, nb_embedding_dims), dtype='float32', name='words_input')\n",
    "    casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "    casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False, name = 'case_embed')(casing_input)\n",
    "    character_input=Input(shape=(None,52,),name='char_input')\n",
    "    embed_char_out=TimeDistributed(Embedding(len(char2Idx),32,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "    kernel_sizes = (3, 4, 5)\n",
    "    conv_blocks = []\n",
    "    for sz in kernel_sizes:\n",
    "        conv = TimeDistributed(Conv1D(\n",
    "                             kernel_size=sz,\n",
    "                             filters=32,\n",
    "                             padding=\"same\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1))(embed_char_out)\n",
    "        conv = TimeDistributed(MaxPooling1D(52))(conv)\n",
    "        conv = TimeDistributed(Flatten())(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    output = concatenate([words_input, casing, conv_blocks[0], conv_blocks[1], conv_blocks[2]])\n",
    "    output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.5))(output)\n",
    "    output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
    "    crf = CRF(len(label2Idx))\n",
    "    output = crf(output)\n",
    "    model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
    "    model.compile(loss=crf.loss_function, optimizer='nadam', metrics=[crf.accuracy])\n",
    "    model.summary()\n",
    "    return(model)\n",
    "\n",
    "def get_model_lstm():\n",
    "    words_input = Input(shape=(None, nb_embedding_dims), dtype='float32', name='words_input')\n",
    "    casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "    casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False, name = 'case_embed')(casing_input)\n",
    "    character_input=Input(shape=(None,nb_char_embedding_dims,),name='char_input')\n",
    "    embed_char_out=TimeDistributed(Embedding(len(char2Idx),32,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "    char_lstm = TimeDistributed(Bidirectional(LSTM(52)))(embed_char_out)\n",
    "    output = concatenate([words_input, casing, char_lstm])\n",
    "    output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.5))(output)\n",
    "    output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
    "    crf = CRF(len(label2Idx))\n",
    "    output = crf(output)\n",
    "    model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
    "    model.compile(loss=crf.loss_function, optimizer='nadam', metrics=[crf.accuracy])\n",
    "    model.summary()\n",
    "    return(model)\n",
    "\n",
    "class F1History(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.f1_scores = []\n",
    "        self.max_f1 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs.get('val_acc'))\n",
    "        true_labels, pred_labels = predict_batches(dev_batches)\n",
    "        pre, rec, f1 = compute_f1(pred_labels, true_labels, idx2Label)\n",
    "        self.f1_scores.append(f1)\n",
    "        if epoch > 30 and f1 > self.max_f1:\n",
    "            print(\"\\nNew maximum F1 score: \" + str(f1) + \" (before: \" + str(self.max_f1) + \") Saving to \" + tmp_model_filename)\n",
    "            self.max_f1 = f1\n",
    "            model.save(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_181 (TimeDistr (None, None, 104)    35360       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, None, 412)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_181[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_35 (Bidirectional (None, None, 400)    980800      concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_182 (TimeDistr (None, None, 25)     10025       bidirectional_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_23 (CRF)                    (None, None, 25)     1325        time_distributed_182[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,038,102\n",
      "Trainable params: 1,038,038\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "10/51 [====>.........................] - ETA: 1:09 - loss: 0.9499 - acc: 0.8401"
     ]
    }
   ],
   "source": [
    "tmp_model_filename = 'tmp_generator_NER_lstm_best.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = F1History()\n",
    "model = get_model_lstm()\n",
    "model.fit_generator(\n",
    "    generator(train_batches), \n",
    "    epochs = 80, steps_per_epoch = len(train_batches), \n",
    "    validation_data = generator(dev_batches), validation_steps = len(dev_batches), \n",
    "    callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'F1History' object has no attribute 'f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-44e8da3f09a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'F1History' object has no attribute 'f1'"
     ]
    }
   ],
   "source": [
    "print(history.acc)\n",
    "print(history.f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = predict_batches(test_batches)\n",
    "print(compute_f1(pred_labels, true_labels, idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_111 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_114 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_117 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_112 (TimeDistr (None, None, 1, 32)  0           time_distributed_111[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_115 (TimeDistr (None, None, 1, 32)  0           time_distributed_114[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_118 (TimeDistr (None, None, 1, 32)  0           time_distributed_117[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_113 (TimeDistr (None, None, 32)     0           time_distributed_112[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_116 (TimeDistr (None, None, 32)     0           time_distributed_115[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_119 (TimeDistr (None, None, 32)     0           time_distributed_118[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_113[0][0]       \n",
      "                                                                 time_distributed_116[0][0]       \n",
      "                                                                 time_distributed_119[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, None, 400)    968000      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_120 (TimeDistr (None, None, 25)     10025       bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_16 (CRF)                    (None, None, 25)     1325        time_distributed_120[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "51/51 [==============================] - 78s 2s/step - loss: 0.5803 - acc: 0.8829 - val_loss: 1.0508 - val_acc: 0.2615\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 25s 491ms/step - loss: 0.3187 - acc: 0.9237 - val_loss: 0.2863 - val_acc: 0.9322\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.3076 - acc: 0.9261 - val_loss: 0.6362 - val_acc: 0.9218\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: 0.2483 - acc: 0.9387 - val_loss: 1.1654 - val_acc: 0.3062\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: 0.2183 - acc: 0.9420 - val_loss: 1.0228 - val_acc: 0.4225\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: 0.1973 - acc: 0.9465 - val_loss: 1.3216 - val_acc: 0.2992\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: 0.1878 - acc: 0.9464 - val_loss: 0.3436 - val_acc: 0.8602\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: 0.1645 - acc: 0.9507 - val_loss: 0.4169 - val_acc: 0.7916\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.1472 - acc: 0.9548 - val_loss: 0.4521 - val_acc: 0.7631\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 23s 446ms/step - loss: 0.1348 - acc: 0.9582 - val_loss: 0.1558 - val_acc: 0.9489\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: 0.1241 - acc: 0.9578 - val_loss: 0.2334 - val_acc: 0.9390\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: 0.1238 - acc: 0.9576 - val_loss: 0.3237 - val_acc: 0.8366\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 23s 447ms/step - loss: 0.1096 - acc: 0.9606 - val_loss: 0.1121 - val_acc: 0.9624\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: 0.0984 - acc: 0.9625 - val_loss: 0.1618 - val_acc: 0.9517\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: 0.1037 - acc: 0.9598 - val_loss: 0.4971 - val_acc: 0.7299\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: 0.0908 - acc: 0.9618 - val_loss: 0.0929 - val_acc: 0.9614\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: 0.0779 - acc: 0.9645 - val_loss: 0.1394 - val_acc: 0.9557\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: 0.0728 - acc: 0.9672 - val_loss: 0.0737 - val_acc: 0.9664\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: 0.0609 - acc: 0.9689 - val_loss: 0.0627 - val_acc: 0.9678\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 23s 443ms/step - loss: 0.0530 - acc: 0.9703 - val_loss: 0.0759 - val_acc: 0.9652\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: 0.0494 - acc: 0.9687 - val_loss: 0.0508 - val_acc: 0.9674\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: 0.0415 - acc: 0.9712 - val_loss: 0.0532 - val_acc: 0.9664\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 23s 453ms/step - loss: 0.0339 - acc: 0.9722 - val_loss: 0.0370 - val_acc: 0.9696\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: 0.0285 - acc: 0.9730 - val_loss: 0.0439 - val_acc: 0.9680\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: 0.0229 - acc: 0.9732 - val_loss: 0.0270 - val_acc: 0.9703\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 24s 461ms/step - loss: 0.0164 - acc: 0.9731 - val_loss: 0.0209 - val_acc: 0.9704\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 23s 444ms/step - loss: 0.0108 - acc: 0.9738 - val_loss: 0.0191 - val_acc: 0.9698\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: 0.0051 - acc: 0.9736 - val_loss: 0.0102 - val_acc: 0.9708\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 23s 455ms/step - loss: -8.6236e-04 - acc: 0.9753 - val_loss: 0.0092 - val_acc: 0.9709\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.0065 - acc: 0.9757 - val_loss: 0.0023 - val_acc: 0.9706\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 23s 447ms/step - loss: -0.0130 - acc: 0.9766 - val_loss: -0.0013 - val_acc: 0.9708\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0181 - acc: 0.9762\n",
      "New maximum F1 score: 0.7691417550626809 (before: 0) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 28s 546ms/step - loss: -0.0179 - acc: 0.9765 - val_loss: -0.0104 - val_acc: 0.9708\n",
      "Epoch 33/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0249 - acc: 0.9772\n",
      "New maximum F1 score: 0.7738974256635401 (before: 0.7691417550626809) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.0247 - acc: 0.9775 - val_loss: -0.0125 - val_acc: 0.9718\n",
      "Epoch 34/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: -0.0296 - acc: 0.9780 - val_loss: -0.0137 - val_acc: 0.9714\n",
      "Epoch 35/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0346 - acc: 0.9775\n",
      "New maximum F1 score: 0.7761016276300118 (before: 0.7738974256635401) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.0342 - acc: 0.9779 - val_loss: -0.0248 - val_acc: 0.9714\n",
      "Epoch 36/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: -0.0408 - acc: 0.9790 - val_loss: -0.0256 - val_acc: 0.9716\n",
      "Epoch 37/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0454 - acc: 0.9781\n",
      "New maximum F1 score: 0.7817524115755627 (before: 0.7761016276300118) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 23s 453ms/step - loss: -0.0448 - acc: 0.9784 - val_loss: -0.0306 - val_acc: 0.9721\n",
      "Epoch 38/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: -0.0492 - acc: 0.9784 - val_loss: -0.0378 - val_acc: 0.9711\n",
      "Epoch 39/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0551 - acc: 0.9787\n",
      "New maximum F1 score: 0.7819430814524044 (before: 0.7817524115755627) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 23s 461ms/step - loss: -0.0544 - acc: 0.9790 - val_loss: -0.0443 - val_acc: 0.9723\n",
      "Epoch 40/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0609 - acc: 0.9794\n",
      "New maximum F1 score: 0.7821605550049554 (before: 0.7819430814524044) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 479ms/step - loss: -0.0602 - acc: 0.9797 - val_loss: -0.0485 - val_acc: 0.9724\n",
      "Epoch 41/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: -0.0651 - acc: 0.9799 - val_loss: -0.0434 - val_acc: 0.9720\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 25s 498ms/step - loss: -0.0707 - acc: 0.9803 - val_loss: -0.0594 - val_acc: 0.9719\n",
      "Epoch 43/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0771 - acc: 0.9807\n",
      "New maximum F1 score: 0.787528868360277 (before: 0.7821605550049554) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 461ms/step - loss: -0.0761 - acc: 0.9809 - val_loss: -0.0637 - val_acc: 0.9727\n",
      "Epoch 44/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.0814 - acc: 0.9812 - val_loss: -0.0623 - val_acc: 0.9729\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: -0.0859 - acc: 0.9812 - val_loss: -0.0699 - val_acc: 0.9724\n",
      "Epoch 46/80\n",
      "51/51 [==============================] - 25s 484ms/step - loss: -0.0903 - acc: 0.9812 - val_loss: -0.0724 - val_acc: 0.9720\n",
      "Epoch 47/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0974 - acc: 0.9819\n",
      "New maximum F1 score: 0.7907965970610982 (before: 0.787528868360277) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.0962 - acc: 0.9821 - val_loss: -0.0811 - val_acc: 0.9733\n",
      "Epoch 48/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.1015 - acc: 0.9822 - val_loss: -0.0823 - val_acc: 0.9724\n",
      "Epoch 49/80\n",
      "51/51 [==============================] - 26s 501ms/step - loss: -0.1063 - acc: 0.9821 - val_loss: -0.0870 - val_acc: 0.9724\n",
      "Epoch 50/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1115 - acc: 0.9821\n",
      "New maximum F1 score: 0.7959984307571597 (before: 0.7907965970610982) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1101 - acc: 0.9823 - val_loss: -0.0950 - val_acc: 0.9737\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1162 - acc: 0.9830 - val_loss: -0.0978 - val_acc: 0.9730\n",
      "Epoch 52/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.1211 - acc: 0.9828 - val_loss: -0.1060 - val_acc: 0.9732\n",
      "Epoch 53/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1264 - acc: 0.9837 - val_loss: -0.1056 - val_acc: 0.9733\n",
      "Epoch 54/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: -0.1311 - acc: 0.9836 - val_loss: -0.1011 - val_acc: 0.9699\n",
      "Epoch 55/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1368 - acc: 0.9837\n",
      "New maximum F1 score: 0.8009376831412386 (before: 0.7959984307571597) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1350 - acc: 0.9839 - val_loss: -0.1177 - val_acc: 0.9740\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1405 - acc: 0.9843 - val_loss: -0.1118 - val_acc: 0.9736\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1452 - acc: 0.9841 - val_loss: -0.1260 - val_acc: 0.9742\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 26s 516ms/step - loss: -0.1499 - acc: 0.9846 - val_loss: -0.1256 - val_acc: 0.9710\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.1529 - acc: 0.9841 - val_loss: -0.1265 - val_acc: 0.9736\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.1586 - acc: 0.9847 - val_loss: -0.1397 - val_acc: 0.9738\n",
      "Epoch 61/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.1628 - acc: 0.9845 - val_loss: -0.1305 - val_acc: 0.9718\n",
      "Epoch 62/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: -0.1671 - acc: 0.9847 - val_loss: -0.1432 - val_acc: 0.9723\n",
      "Epoch 63/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1757 - acc: 0.9853\n",
      "New maximum F1 score: 0.8026897214217099 (before: 0.8009376831412386) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1734 - acc: 0.9854 - val_loss: -0.1553 - val_acc: 0.9743\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.1786 - acc: 0.9855 - val_loss: -0.1583 - val_acc: 0.9736\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.1832 - acc: 0.9856 - val_loss: -0.1617 - val_acc: 0.9725\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 25s 499ms/step - loss: -0.1875 - acc: 0.9860 - val_loss: -0.1646 - val_acc: 0.9743\n",
      "Epoch 67/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1957 - acc: 0.9861\n",
      "New maximum F1 score: 0.8027000964320153 (before: 0.8026897214217099) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1932 - acc: 0.9863 - val_loss: -0.1691 - val_acc: 0.9739\n",
      "Epoch 68/80\n",
      "51/51 [==============================] - 24s 461ms/step - loss: -0.1974 - acc: 0.9862 - val_loss: -0.1738 - val_acc: 0.9729\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.2021 - acc: 0.9864 - val_loss: -0.1774 - val_acc: 0.9732\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2068 - acc: 0.9866 - val_loss: -0.1835 - val_acc: 0.9745\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.2124 - acc: 0.9872 - val_loss: -0.1861 - val_acc: 0.9742\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 25s 481ms/step - loss: -0.2163 - acc: 0.9870 - val_loss: -0.1831 - val_acc: 0.9739\n",
      "Epoch 73/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2239 - acc: 0.9871\n",
      "New maximum F1 score: 0.8092552984639315 (before: 0.8027000964320153) Saving to tmp_generator_NER_lstm_best.0.h5\n",
      "51/51 [==============================] - 24s 479ms/step - loss: -0.2211 - acc: 0.9873 - val_loss: -0.1976 - val_acc: 0.9751\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2258 - acc: 0.9874 - val_loss: -0.1978 - val_acc: 0.9737\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.2303 - acc: 0.9875 - val_loss: -0.2044 - val_acc: 0.9751\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.2356 - acc: 0.9880 - val_loss: -0.2062 - val_acc: 0.9733\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2397 - acc: 0.9879 - val_loss: -0.2130 - val_acc: 0.9737\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.2441 - acc: 0.9881 - val_loss: -0.2077 - val_acc: 0.9734\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.2479 - acc: 0.9877 - val_loss: -0.2159 - val_acc: 0.9726\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2517 - acc: 0.9873 - val_loss: -0.2069 - val_acc: 0.9718\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_121 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_124 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_127 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_122 (TimeDistr (None, None, 1, 32)  0           time_distributed_121[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_125 (TimeDistr (None, None, 1, 32)  0           time_distributed_124[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_128 (TimeDistr (None, None, 1, 32)  0           time_distributed_127[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_123 (TimeDistr (None, None, 32)     0           time_distributed_122[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_126 (TimeDistr (None, None, 32)     0           time_distributed_125[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_129 (TimeDistr (None, None, 32)     0           time_distributed_128[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_123[0][0]       \n",
      "                                                                 time_distributed_126[0][0]       \n",
      "                                                                 time_distributed_129[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, None, 400)    968000      concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_130 (TimeDistr (None, None, 25)     10025       bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_17 (CRF)                    (None, None, 25)     1325        time_distributed_130[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "51/51 [==============================] - 37s 721ms/step - loss: 0.5926 - acc: 0.8772 - val_loss: 0.9248 - val_acc: 0.8685\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: 0.3264 - acc: 0.9242 - val_loss: 1.2276 - val_acc: 0.2504\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 25s 481ms/step - loss: 0.2828 - acc: 0.9329 - val_loss: 0.7363 - val_acc: 0.6725\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: 0.2454 - acc: 0.9393 - val_loss: 0.8988 - val_acc: 0.4585\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: 0.2185 - acc: 0.9445 - val_loss: 0.8862 - val_acc: 0.5359\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 24s 461ms/step - loss: 0.1959 - acc: 0.9462 - val_loss: 0.8710 - val_acc: 0.5413\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: 0.1822 - acc: 0.9489 - val_loss: 0.3507 - val_acc: 0.8729\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 23s 453ms/step - loss: 0.1619 - acc: 0.9528 - val_loss: 0.1802 - val_acc: 0.9552\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 0.1499 - acc: 0.9558 - val_loss: 0.7035 - val_acc: 0.6128\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: 0.1459 - acc: 0.9548 - val_loss: 0.2980 - val_acc: 0.8815\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: 0.1308 - acc: 0.9592 - val_loss: 0.1326 - val_acc: 0.9607\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: 0.1144 - acc: 0.9618 - val_loss: 0.1773 - val_acc: 0.9544\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: 0.1133 - acc: 0.9616 - val_loss: 0.1185 - val_acc: 0.9615\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: 0.0990 - acc: 0.9661 - val_loss: 0.1268 - val_acc: 0.9600\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: 0.0905 - acc: 0.9669 - val_loss: 0.1039 - val_acc: 0.9640\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 0.0807 - acc: 0.9680 - val_loss: 0.1025 - val_acc: 0.9641\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.0745 - acc: 0.9687 - val_loss: 0.0935 - val_acc: 0.9648\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0697 - acc: 0.9687 - val_loss: 0.0866 - val_acc: 0.9630\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 0.0637 - acc: 0.9699 - val_loss: 0.1127 - val_acc: 0.9619\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: 0.0586 - acc: 0.9704 - val_loss: 0.0785 - val_acc: 0.9645\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.0506 - acc: 0.9701 - val_loss: 0.0538 - val_acc: 0.9680\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.0441 - acc: 0.9710 - val_loss: 0.0785 - val_acc: 0.9649\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: 0.0381 - acc: 0.9723 - val_loss: 0.0474 - val_acc: 0.9688\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: 0.0295 - acc: 0.9733 - val_loss: 0.0466 - val_acc: 0.9675\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: 0.0236 - acc: 0.9744 - val_loss: 0.0378 - val_acc: 0.9687\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: 0.0172 - acc: 0.9744 - val_loss: 0.0412 - val_acc: 0.9680\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: 0.0126 - acc: 0.9751 - val_loss: 0.0443 - val_acc: 0.9679\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: 0.0082 - acc: 0.9750 - val_loss: 0.0144 - val_acc: 0.9708\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -3.5504e-04 - acc: 0.9762 - val_loss: 0.0088 - val_acc: 0.9714\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: -0.0055 - acc: 0.9767 - val_loss: 0.0102 - val_acc: 0.9709\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.0107 - acc: 0.9773 - val_loss: 0.0073 - val_acc: 0.9701\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0168 - acc: 0.9773\n",
      "New maximum F1 score: 0.7746397694524496 (before: 0) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 29s 560ms/step - loss: -0.0166 - acc: 0.9776 - val_loss: -0.0053 - val_acc: 0.9711\n",
      "Epoch 33/80\n",
      "51/51 [==============================] - 23s 446ms/step - loss: -0.0226 - acc: 0.9780 - val_loss: -0.0074 - val_acc: 0.9720\n",
      "Epoch 34/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0282 - acc: 0.9783\n",
      "New maximum F1 score: 0.7796676441837732 (before: 0.7746397694524496) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.0278 - acc: 0.9786 - val_loss: -0.0148 - val_acc: 0.9722\n",
      "Epoch 35/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.0333 - acc: 0.9788 - val_loss: -0.0152 - val_acc: 0.9720\n",
      "Epoch 36/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.0383 - acc: 0.9791 - val_loss: -0.0261 - val_acc: 0.9714\n",
      "Epoch 37/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.0431 - acc: 0.9795 - val_loss: -0.0179 - val_acc: 0.9708\n",
      "Epoch 38/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0480 - acc: 0.9794\n",
      "New maximum F1 score: 0.7799272170082359 (before: 0.7796676441837732) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.0474 - acc: 0.9797 - val_loss: -0.0337 - val_acc: 0.9718\n",
      "Epoch 39/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0543 - acc: 0.9798\n",
      "New maximum F1 score: 0.7869994196169472 (before: 0.7799272170082359) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 25s 481ms/step - loss: -0.0537 - acc: 0.9801 - val_loss: -0.0405 - val_acc: 0.9728\n",
      "Epoch 40/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: -0.0596 - acc: 0.9807 - val_loss: -0.0417 - val_acc: 0.9726\n",
      "Epoch 41/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0646 - acc: 0.9804\n",
      "New maximum F1 score: 0.7904191616766466 (before: 0.7869994196169472) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.0639 - acc: 0.9807 - val_loss: -0.0491 - val_acc: 0.9731\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.0695 - acc: 0.9815 - val_loss: -0.0513 - val_acc: 0.9722\n",
      "Epoch 43/80\n",
      "51/51 [==============================] - 23s 447ms/step - loss: -0.0745 - acc: 0.9815 - val_loss: -0.0589 - val_acc: 0.9729\n",
      "Epoch 44/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: -0.0803 - acc: 0.9823 - val_loss: -0.0636 - val_acc: 0.9730\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: -0.0852 - acc: 0.9823 - val_loss: -0.0667 - val_acc: 0.9731\n",
      "Epoch 46/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0913 - acc: 0.9823\n",
      "New maximum F1 score: 0.794621979734996 (before: 0.7904191616766466) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.0902 - acc: 0.9825 - val_loss: -0.0708 - val_acc: 0.9734\n",
      "Epoch 47/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0962 - acc: 0.9825\n",
      "New maximum F1 score: 0.7958545170121236 (before: 0.794621979734996) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 452ms/step - loss: -0.0951 - acc: 0.9827 - val_loss: -0.0760 - val_acc: 0.9734\n",
      "Epoch 48/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: -0.1000 - acc: 0.9832 - val_loss: -0.0680 - val_acc: 0.9734\n",
      "Epoch 49/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1057 - acc: 0.9832\n",
      "New maximum F1 score: 0.7971461627458541 (before: 0.7958545170121236) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 444ms/step - loss: -0.1044 - acc: 0.9834 - val_loss: -0.0851 - val_acc: 0.9735\n",
      "Epoch 50/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: -0.1090 - acc: 0.9834 - val_loss: -0.0915 - val_acc: 0.9736\n",
      "Epoch 51/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1149 - acc: 0.9831\n",
      "New maximum F1 score: 0.8000774893452149 (before: 0.7971461627458541) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 456ms/step - loss: -0.1134 - acc: 0.9834 - val_loss: -0.0954 - val_acc: 0.9748\n",
      "Epoch 52/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1204 - acc: 0.9833\n",
      "New maximum F1 score: 0.8019193857965452 (before: 0.8000774893452149) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.1189 - acc: 0.9835 - val_loss: -0.1015 - val_acc: 0.9745\n",
      "Epoch 53/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1259 - acc: 0.9842\n",
      "New maximum F1 score: 0.8038424591738714 (before: 0.8019193857965452) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 453ms/step - loss: -0.1243 - acc: 0.9843 - val_loss: -0.1056 - val_acc: 0.9746\n",
      "Epoch 54/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.1296 - acc: 0.9844 - val_loss: -0.1103 - val_acc: 0.9738\n",
      "Epoch 55/80\n",
      "51/51 [==============================] - 24s 473ms/step - loss: -0.1346 - acc: 0.9848 - val_loss: -0.1119 - val_acc: 0.9739\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1381 - acc: 0.9846 - val_loss: -0.0969 - val_acc: 0.9639\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1345 - acc: 0.9817 - val_loss: 0.0207 - val_acc: 0.9575\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1247 - acc: 0.9776 - val_loss: -0.0946 - val_acc: 0.9695\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.1304 - acc: 0.9780 - val_loss: 0.2180 - val_acc: 0.8099\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: -0.1340 - acc: 0.9777 - val_loss: -0.0407 - val_acc: 0.9639\n",
      "Epoch 61/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.1381 - acc: 0.9784 - val_loss: -0.0021 - val_acc: 0.9021\n",
      "Epoch 62/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: -0.1519 - acc: 0.9813 - val_loss: -0.1418 - val_acc: 0.9745\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 23s 456ms/step - loss: -0.1626 - acc: 0.9831 - val_loss: -0.1489 - val_acc: 0.9745\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: -0.1689 - acc: 0.9840 - val_loss: -0.1536 - val_acc: 0.9739\n",
      "Epoch 65/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1764 - acc: 0.9842\n",
      "New maximum F1 score: 0.8051400076716534 (before: 0.8038424591738714) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.1742 - acc: 0.9844 - val_loss: -0.1596 - val_acc: 0.9745\n",
      "Epoch 66/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1820 - acc: 0.9846\n",
      "New maximum F1 score: 0.8086325439266616 (before: 0.8051400076716534) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.1797 - acc: 0.9848 - val_loss: -0.1644 - val_acc: 0.9751\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1853 - acc: 0.9854 - val_loss: -0.1660 - val_acc: 0.9748\n",
      "Epoch 68/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.1894 - acc: 0.9853 - val_loss: -0.1719 - val_acc: 0.9744\n",
      "Epoch 69/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1973 - acc: 0.9853\n",
      "New maximum F1 score: 0.81143295607136 (before: 0.8086325439266616) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 23s 453ms/step - loss: -0.1948 - acc: 0.9855 - val_loss: -0.1784 - val_acc: 0.9752\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1999 - acc: 0.9859 - val_loss: -0.1807 - val_acc: 0.9751\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.2051 - acc: 0.9865 - val_loss: -0.1843 - val_acc: 0.9746\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: -0.2091 - acc: 0.9863 - val_loss: -0.1883 - val_acc: 0.9736\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.2137 - acc: 0.9864 - val_loss: -0.1958 - val_acc: 0.9742\n",
      "Epoch 74/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2212 - acc: 0.9866\n",
      "New maximum F1 score: 0.8151131568853088 (before: 0.81143295607136) Saving to tmp_generator_NER_lstm_best.1.h5\n",
      "51/51 [==============================] - 24s 477ms/step - loss: -0.2184 - acc: 0.9868 - val_loss: -0.2004 - val_acc: 0.9758\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.2234 - acc: 0.9868 - val_loss: -0.2041 - val_acc: 0.9745\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.2283 - acc: 0.9872 - val_loss: -0.2088 - val_acc: 0.9752\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 23s 447ms/step - loss: -0.2325 - acc: 0.9871 - val_loss: -0.2128 - val_acc: 0.9752\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: -0.2374 - acc: 0.9871 - val_loss: -0.2148 - val_acc: 0.9744\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 23s 449ms/step - loss: -0.2414 - acc: 0.9872 - val_loss: -0.2213 - val_acc: 0.9750\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: -0.2464 - acc: 0.9875 - val_loss: -0.2258 - val_acc: 0.9744\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_131 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_134 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_137 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_132 (TimeDistr (None, None, 1, 32)  0           time_distributed_131[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_135 (TimeDistr (None, None, 1, 32)  0           time_distributed_134[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_138 (TimeDistr (None, None, 1, 32)  0           time_distributed_137[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_133 (TimeDistr (None, None, 32)     0           time_distributed_132[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_136 (TimeDistr (None, None, 32)     0           time_distributed_135[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_139 (TimeDistr (None, None, 32)     0           time_distributed_138[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_133[0][0]       \n",
      "                                                                 time_distributed_136[0][0]       \n",
      "                                                                 time_distributed_139[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, None, 400)    968000      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_140 (TimeDistr (None, None, 25)     10025       bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_18 (CRF)                    (None, None, 25)     1325        time_distributed_140[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "51/51 [==============================] - 37s 721ms/step - loss: 0.5895 - acc: 0.8807 - val_loss: 1.2610 - val_acc: 0.1921\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.3123 - acc: 0.9263 - val_loss: 1.9533 - val_acc: 0.0623\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: 0.2645 - acc: 0.9346 - val_loss: 0.8365 - val_acc: 0.4594\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: 0.2256 - acc: 0.9415 - val_loss: 1.0809 - val_acc: 0.3608\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 24s 473ms/step - loss: 0.2007 - acc: 0.9448 - val_loss: 0.9272 - val_acc: 0.4710\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: 0.1840 - acc: 0.9478 - val_loss: 1.9272 - val_acc: 0.2383\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.1652 - acc: 0.9505 - val_loss: 0.2185 - val_acc: 0.9406\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: 0.1446 - acc: 0.9547 - val_loss: 0.1424 - val_acc: 0.9576\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 0.1317 - acc: 0.9568 - val_loss: 0.9227 - val_acc: 0.5090\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: 0.1281 - acc: 0.9594 - val_loss: 0.1339 - val_acc: 0.9586\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.1091 - acc: 0.9617 - val_loss: 0.1182 - val_acc: 0.9586\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: 0.1003 - acc: 0.9636 - val_loss: 0.1019 - val_acc: 0.9644\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: 0.0935 - acc: 0.9625 - val_loss: 0.1494 - val_acc: 0.9566\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 23s 453ms/step - loss: 0.0925 - acc: 0.9636 - val_loss: 0.2311 - val_acc: 0.8941\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 0.0834 - acc: 0.9635 - val_loss: 0.0866 - val_acc: 0.9648\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: 0.0688 - acc: 0.9686 - val_loss: 0.0775 - val_acc: 0.9656\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: 0.0618 - acc: 0.9686 - val_loss: 0.0887 - val_acc: 0.9632\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.0551 - acc: 0.9689 - val_loss: 0.0603 - val_acc: 0.9672\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: 0.0491 - acc: 0.9700 - val_loss: 0.0642 - val_acc: 0.9657\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0418 - acc: 0.9697 - val_loss: 0.0748 - val_acc: 0.9564\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: 0.0415 - acc: 0.9689 - val_loss: 0.1084 - val_acc: 0.9591\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: 0.0366 - acc: 0.9701 - val_loss: 0.0403 - val_acc: 0.9656\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: 0.0251 - acc: 0.9720 - val_loss: 0.0309 - val_acc: 0.9691\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0181 - acc: 0.9729 - val_loss: 0.0546 - val_acc: 0.9659\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.0152 - acc: 0.9731 - val_loss: 0.0165 - val_acc: 0.9693\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: 0.0054 - acc: 0.9744 - val_loss: 0.0167 - val_acc: 0.9698\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 25s 485ms/step - loss: -0.0015 - acc: 0.9757 - val_loss: 0.0127 - val_acc: 0.9700\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 24s 479ms/step - loss: -0.0061 - acc: 0.9757 - val_loss: 0.0032 - val_acc: 0.9709\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0110 - acc: 0.9755 - val_loss: -0.0035 - val_acc: 0.9703\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.0175 - acc: 0.9766 - val_loss: -0.0088 - val_acc: 0.9710\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0230 - acc: 0.9767 - val_loss: -0.0121 - val_acc: 0.9699\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0291 - acc: 0.9769\n",
      "New maximum F1 score: 0.7655367231638418 (before: 0) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 30s 586ms/step - loss: -0.0285 - acc: 0.9772 - val_loss: -0.0075 - val_acc: 0.9705\n",
      "Epoch 33/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0344 - acc: 0.9774\n",
      "New maximum F1 score: 0.7743362831858408 (before: 0.7655367231638418) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.0340 - acc: 0.9777 - val_loss: -0.0181 - val_acc: 0.9717\n",
      "Epoch 34/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.0400 - acc: 0.9782 - val_loss: -0.0281 - val_acc: 0.9711\n",
      "Epoch 35/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.0444 - acc: 0.9780 - val_loss: -0.0267 - val_acc: 0.9671\n",
      "Epoch 36/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0489 - acc: 0.9781\n",
      "New maximum F1 score: 0.7799288818648756 (before: 0.7743362831858408) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.0484 - acc: 0.9784 - val_loss: -0.0378 - val_acc: 0.9723\n",
      "Epoch 37/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.0552 - acc: 0.9792 - val_loss: -0.0404 - val_acc: 0.9719\n",
      "Epoch 38/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0615 - acc: 0.9793\n",
      "New maximum F1 score: 0.7832058073376496 (before: 0.7799288818648756) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.0608 - acc: 0.9795 - val_loss: -0.0490 - val_acc: 0.9721\n",
      "Epoch 39/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0667 - acc: 0.9799\n",
      "New maximum F1 score: 0.7844998022933967 (before: 0.7832058073376496) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.0659 - acc: 0.9801 - val_loss: -0.0519 - val_acc: 0.9724\n",
      "Epoch 40/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.0714 - acc: 0.9803 - val_loss: -0.0559 - val_acc: 0.9721\n",
      "Epoch 41/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0760 - acc: 0.9806 - val_loss: -0.0620 - val_acc: 0.9723\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.0814 - acc: 0.9809 - val_loss: -0.0621 - val_acc: 0.9717\n",
      "Epoch 43/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: -0.0862 - acc: 0.9811 - val_loss: -0.0716 - val_acc: 0.9722\n",
      "Epoch 44/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0920 - acc: 0.9810\n",
      "New maximum F1 score: 0.7869868319132456 (before: 0.7844998022933967) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0908 - acc: 0.9812 - val_loss: -0.0788 - val_acc: 0.9723\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.0964 - acc: 0.9819 - val_loss: -0.0784 - val_acc: 0.9722\n",
      "Epoch 46/80\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.1015 - acc: 0.9823 - val_loss: -0.0866 - val_acc: 0.9724\n",
      "Epoch 47/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1076 - acc: 0.9819\n",
      "New maximum F1 score: 0.791226008617313 (before: 0.7869868319132456) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1063 - acc: 0.9821 - val_loss: -0.0902 - val_acc: 0.9734\n",
      "Epoch 48/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.1117 - acc: 0.9826 - val_loss: -0.0953 - val_acc: 0.9729\n",
      "Epoch 49/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: -0.1160 - acc: 0.9826 - val_loss: -0.0946 - val_acc: 0.9733\n",
      "Epoch 50/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.1208 - acc: 0.9832 - val_loss: -0.0955 - val_acc: 0.9726\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1256 - acc: 0.9831 - val_loss: -0.1074 - val_acc: 0.9736\n",
      "Epoch 52/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1331 - acc: 0.9837\n",
      "New maximum F1 score: 0.7927720107650903 (before: 0.791226008617313) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 480ms/step - loss: -0.1314 - acc: 0.9838 - val_loss: -0.1139 - val_acc: 0.9733\n",
      "Epoch 53/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1383 - acc: 0.9838\n",
      "New maximum F1 score: 0.7993821201004054 (before: 0.7927720107650903) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.1366 - acc: 0.9840 - val_loss: -0.1198 - val_acc: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.1409 - acc: 0.9839 - val_loss: -0.1230 - val_acc: 0.9740\n",
      "Epoch 55/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.1456 - acc: 0.9842 - val_loss: -0.1237 - val_acc: 0.9737\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: -0.1510 - acc: 0.9848 - val_loss: -0.1273 - val_acc: 0.9739\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1551 - acc: 0.9848 - val_loss: -0.1365 - val_acc: 0.9743\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1606 - acc: 0.9852 - val_loss: -0.1365 - val_acc: 0.9716\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.1641 - acc: 0.9850 - val_loss: -0.1442 - val_acc: 0.9744\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.1695 - acc: 0.9852 - val_loss: -0.1491 - val_acc: 0.9731\n",
      "Epoch 61/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1764 - acc: 0.9854\n",
      "New maximum F1 score: 0.7996101364522418 (before: 0.7993821201004054) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1742 - acc: 0.9855 - val_loss: -0.1536 - val_acc: 0.9747\n",
      "Epoch 62/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1811 - acc: 0.9851\n",
      "New maximum F1 score: 0.802654028436019 (before: 0.7996101364522418) Saving to tmp_generator_NER_lstm_best.2.h5\n",
      "51/51 [==============================] - 25s 484ms/step - loss: -0.1788 - acc: 0.9853 - val_loss: -0.1610 - val_acc: 0.9743\n",
      "Epoch 63/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.1839 - acc: 0.9857 - val_loss: -0.1657 - val_acc: 0.9752\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.1894 - acc: 0.9865 - val_loss: -0.1640 - val_acc: 0.9743\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.1944 - acc: 0.9864 - val_loss: -0.1715 - val_acc: 0.9741\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: -0.1988 - acc: 0.9865 - val_loss: -0.1772 - val_acc: 0.9739\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.2034 - acc: 0.9868 - val_loss: -0.1815 - val_acc: 0.9744\n",
      "Epoch 68/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2085 - acc: 0.9870 - val_loss: -0.1867 - val_acc: 0.9741\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2126 - acc: 0.9870 - val_loss: -0.1796 - val_acc: 0.9691\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2084 - acc: 0.9847 - val_loss: -0.1307 - val_acc: 0.9699\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.2014 - acc: 0.9810 - val_loss: 0.7953 - val_acc: 0.5755\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 25s 484ms/step - loss: -0.2046 - acc: 0.9803 - val_loss: -0.1650 - val_acc: 0.9713\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.2164 - acc: 0.9821 - val_loss: -0.1980 - val_acc: 0.9683\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2251 - acc: 0.9839 - val_loss: -0.1982 - val_acc: 0.9741\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.2311 - acc: 0.9842 - val_loss: -0.2168 - val_acc: 0.9727\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.2370 - acc: 0.9852 - val_loss: -0.2166 - val_acc: 0.9744\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2437 - acc: 0.9859 - val_loss: -0.2253 - val_acc: 0.9748\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2478 - acc: 0.9862 - val_loss: -0.2145 - val_acc: 0.9730\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2509 - acc: 0.9857 - val_loss: -0.2313 - val_acc: 0.9737\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.2566 - acc: 0.9865 - val_loss: -0.2385 - val_acc: 0.9748\n",
      "Run 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_141 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_144 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_147 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_142 (TimeDistr (None, None, 1, 32)  0           time_distributed_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_145 (TimeDistr (None, None, 1, 32)  0           time_distributed_144[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_148 (TimeDistr (None, None, 1, 32)  0           time_distributed_147[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_143 (TimeDistr (None, None, 32)     0           time_distributed_142[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_146 (TimeDistr (None, None, 32)     0           time_distributed_145[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_149 (TimeDistr (None, None, 32)     0           time_distributed_148[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_143[0][0]       \n",
      "                                                                 time_distributed_146[0][0]       \n",
      "                                                                 time_distributed_149[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, None, 400)    968000      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_150 (TimeDistr (None, None, 25)     10025       bidirectional_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_19 (CRF)                    (None, None, 25)     1325        time_distributed_150[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "51/51 [==============================] - 40s 779ms/step - loss: 0.5877 - acc: 0.8821 - val_loss: 1.2263 - val_acc: 0.2351\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.3155 - acc: 0.9262 - val_loss: 1.2273 - val_acc: 0.2840\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.2680 - acc: 0.9347 - val_loss: 0.4971 - val_acc: 0.8848\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: 0.2333 - acc: 0.9393 - val_loss: 0.9707 - val_acc: 0.4504\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.2011 - acc: 0.9440 - val_loss: 0.3349 - val_acc: 0.9004\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: 0.1748 - acc: 0.9480 - val_loss: 1.4240 - val_acc: 0.3071\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: 0.1742 - acc: 0.9473 - val_loss: 1.4561 - val_acc: 0.3064\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 0.1592 - acc: 0.9494 - val_loss: 0.4085 - val_acc: 0.8302\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.1401 - acc: 0.9533 - val_loss: 0.4492 - val_acc: 0.7827\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.1293 - acc: 0.9543 - val_loss: 0.2230 - val_acc: 0.9179\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 0.1180 - acc: 0.9576 - val_loss: 0.1797 - val_acc: 0.9527\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 24s 478ms/step - loss: 0.1168 - acc: 0.9577 - val_loss: 0.2762 - val_acc: 0.8800\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: 0.1007 - acc: 0.9615 - val_loss: 0.1033 - val_acc: 0.9610\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 23s 456ms/step - loss: 0.0870 - acc: 0.9638 - val_loss: 0.1028 - val_acc: 0.9629\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.0788 - acc: 0.9657 - val_loss: 0.1078 - val_acc: 0.9602\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: 0.0705 - acc: 0.9672 - val_loss: 0.0882 - val_acc: 0.9638\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0622 - acc: 0.9677 - val_loss: 0.0656 - val_acc: 0.9667\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: 0.0553 - acc: 0.9684 - val_loss: 0.0616 - val_acc: 0.9659\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: 0.0530 - acc: 0.9660 - val_loss: 0.1295 - val_acc: 0.9570\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: 0.0602 - acc: 0.9633 - val_loss: 0.2926 - val_acc: 0.8614\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0478 - acc: 0.9680 - val_loss: 0.0550 - val_acc: 0.9649\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: 0.0353 - acc: 0.9696 - val_loss: 0.0532 - val_acc: 0.9649\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: 0.0261 - acc: 0.9715 - val_loss: 0.0295 - val_acc: 0.9683\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: 0.0193 - acc: 0.9722 - val_loss: 0.0413 - val_acc: 0.9663\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: 0.0138 - acc: 0.9723 - val_loss: 0.0179 - val_acc: 0.9697\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 24s 478ms/step - loss: 0.0079 - acc: 0.9734 - val_loss: 0.0152 - val_acc: 0.9696\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: 0.0018 - acc: 0.9741 - val_loss: 0.0128 - val_acc: 0.9695\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.0043 - acc: 0.9747 - val_loss: 0.0011 - val_acc: 0.9701\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.0100 - acc: 0.9749 - val_loss: 0.0022 - val_acc: 0.9698\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.0158 - acc: 0.9755 - val_loss: -0.0020 - val_acc: 0.9702\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 24s 477ms/step - loss: -0.0211 - acc: 0.9756 - val_loss: -0.0150 - val_acc: 0.9697\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0265 - acc: 0.9760\n",
      "New maximum F1 score: 0.7708131185717058 (before: 0) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 31s 607ms/step - loss: -0.0262 - acc: 0.9763 - val_loss: -0.0194 - val_acc: 0.9711\n",
      "Epoch 33/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0333 - acc: 0.9768\n",
      "New maximum F1 score: 0.7729697688203913 (before: 0.7708131185717058) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.0329 - acc: 0.9771 - val_loss: -0.0233 - val_acc: 0.9710\n",
      "Epoch 34/80\n",
      "51/51 [==============================] - 24s 474ms/step - loss: -0.0370 - acc: 0.9773 - val_loss: -0.0309 - val_acc: 0.9705\n",
      "Epoch 35/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0427 - acc: 0.9770\n",
      "New maximum F1 score: 0.7736036573245875 (before: 0.7729697688203913) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0423 - acc: 0.9773 - val_loss: -0.0300 - val_acc: 0.9712\n",
      "Epoch 36/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0497 - acc: 0.9780\n",
      "New maximum F1 score: 0.7777777777777779 (before: 0.7736036573245875) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.0489 - acc: 0.9783 - val_loss: -0.0406 - val_acc: 0.9719\n",
      "Epoch 37/80\n",
      "51/51 [==============================] - 24s 473ms/step - loss: -0.0540 - acc: 0.9786 - val_loss: -0.0419 - val_acc: 0.9716\n",
      "Epoch 38/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.0583 - acc: 0.9788 - val_loss: -0.0459 - val_acc: 0.9715\n",
      "Epoch 39/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0648 - acc: 0.9793 - val_loss: -0.0479 - val_acc: 0.9711\n",
      "Epoch 40/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0704 - acc: 0.9796\n",
      "New maximum F1 score: 0.781135707410972 (before: 0.7777777777777779) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.0695 - acc: 0.9799 - val_loss: -0.0602 - val_acc: 0.9715\n",
      "Epoch 41/80\n",
      "51/51 [==============================] - 24s 476ms/step - loss: -0.0751 - acc: 0.9799 - val_loss: -0.0610 - val_acc: 0.9720\n",
      "Epoch 42/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0808 - acc: 0.9803\n",
      "New maximum F1 score: 0.7861562258313999 (before: 0.781135707410972) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 25s 486ms/step - loss: -0.0797 - acc: 0.9805 - val_loss: -0.0704 - val_acc: 0.9725\n",
      "Epoch 43/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.0848 - acc: 0.9805 - val_loss: -0.0712 - val_acc: 0.9731\n",
      "Epoch 44/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.0898 - acc: 0.9807 - val_loss: -0.0781 - val_acc: 0.9732\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.0954 - acc: 0.9812 - val_loss: -0.0787 - val_acc: 0.9725\n",
      "Epoch 46/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1023 - acc: 0.9812\n",
      "New maximum F1 score: 0.7884908536585366 (before: 0.7861562258313999) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.1010 - acc: 0.9815 - val_loss: -0.0865 - val_acc: 0.9724\n",
      "Epoch 47/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.1055 - acc: 0.9815 - val_loss: -0.0917 - val_acc: 0.9729\n",
      "Epoch 48/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: -0.1111 - acc: 0.9823 - val_loss: -0.0964 - val_acc: 0.9720\n",
      "Epoch 49/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1168 - acc: 0.9821\n",
      "New maximum F1 score: 0.7934952978056427 (before: 0.7884908536585366) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.1154 - acc: 0.9824 - val_loss: -0.1009 - val_acc: 0.9737\n",
      "Epoch 50/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 27s 531ms/step - loss: -0.1208 - acc: 0.9826 - val_loss: -0.0956 - val_acc: 0.9723\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.1256 - acc: 0.9830 - val_loss: -0.1082 - val_acc: 0.9731\n",
      "Epoch 52/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: -0.1310 - acc: 0.9835 - val_loss: -0.1141 - val_acc: 0.9731\n",
      "Epoch 53/80\n",
      "51/51 [==============================] - 28s 551ms/step - loss: -0.1360 - acc: 0.9835 - val_loss: -0.1176 - val_acc: 0.9731\n",
      "Epoch 54/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1428 - acc: 0.9835\n",
      "New maximum F1 score: 0.7956403269754768 (before: 0.7934952978056427) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1410 - acc: 0.9837 - val_loss: -0.1234 - val_acc: 0.9734\n",
      "Epoch 55/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1473 - acc: 0.9836\n",
      "New maximum F1 score: 0.7999216914643696 (before: 0.7956403269754768) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 23s 459ms/step - loss: -0.1455 - acc: 0.9838 - val_loss: -0.1266 - val_acc: 0.9747\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 30s 585ms/step - loss: -0.1502 - acc: 0.9841 - val_loss: -0.1323 - val_acc: 0.9735\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: -0.1550 - acc: 0.9844 - val_loss: -0.1343 - val_acc: 0.9736\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 23s 452ms/step - loss: -0.1593 - acc: 0.9844 - val_loss: -0.1303 - val_acc: 0.9691\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: -0.1619 - acc: 0.9843 - val_loss: -0.1294 - val_acc: 0.9699\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.1667 - acc: 0.9842 - val_loss: -0.1470 - val_acc: 0.9735\n",
      "Epoch 61/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.1731 - acc: 0.9848 - val_loss: -0.1554 - val_acc: 0.9743\n",
      "Epoch 62/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1780 - acc: 0.9851 - val_loss: -0.1606 - val_acc: 0.9737\n",
      "Epoch 63/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1853 - acc: 0.9852\n",
      "New maximum F1 score: 0.8013029315960911 (before: 0.7999216914643696) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 37s 716ms/step - loss: -0.1830 - acc: 0.9854 - val_loss: -0.1648 - val_acc: 0.9739\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1887 - acc: 0.9859 - val_loss: -0.1682 - val_acc: 0.9745\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.1933 - acc: 0.9858 - val_loss: -0.1729 - val_acc: 0.9742\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 29s 571ms/step - loss: -0.1983 - acc: 0.9861 - val_loss: -0.1742 - val_acc: 0.9741\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 23s 453ms/step - loss: -0.2030 - acc: 0.9861 - val_loss: -0.1777 - val_acc: 0.9727\n",
      "Epoch 68/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2102 - acc: 0.9862\n",
      "New maximum F1 score: 0.8017654960660142 (before: 0.8013029315960911) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.2075 - acc: 0.9864 - val_loss: -0.1847 - val_acc: 0.9745\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 26s 515ms/step - loss: -0.2126 - acc: 0.9866 - val_loss: -0.1902 - val_acc: 0.9745\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 25s 485ms/step - loss: -0.2173 - acc: 0.9870 - val_loss: -0.1959 - val_acc: 0.9736\n",
      "Epoch 71/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2248 - acc: 0.9872\n",
      "New maximum F1 score: 0.8066001534919416 (before: 0.8017654960660142) Saving to tmp_generator_NER_lstm_best.3.h5\n",
      "51/51 [==============================] - 23s 445ms/step - loss: -0.2219 - acc: 0.9873 - val_loss: -0.2006 - val_acc: 0.9745\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 23s 450ms/step - loss: -0.2265 - acc: 0.9872 - val_loss: -0.1997 - val_acc: 0.9738\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 23s 442ms/step - loss: -0.2313 - acc: 0.9875 - val_loss: -0.2081 - val_acc: 0.9746\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2356 - acc: 0.9874 - val_loss: -0.2068 - val_acc: 0.9732\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 23s 454ms/step - loss: -0.2401 - acc: 0.9875 - val_loss: -0.2158 - val_acc: 0.9750\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 28s 553ms/step - loss: -0.2440 - acc: 0.9874 - val_loss: -0.2205 - val_acc: 0.9754\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.2502 - acc: 0.9883 - val_loss: -0.2236 - val_acc: 0.9747\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 24s 463ms/step - loss: -0.2539 - acc: 0.9880 - val_loss: -0.2288 - val_acc: 0.9749\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.2586 - acc: 0.9881 - val_loss: -0.2236 - val_acc: 0.9730\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: -0.2626 - acc: 0.9881 - val_loss: -0.2361 - val_acc: 0.9750\n",
      "Run 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_151 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_154 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_157 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_152 (TimeDistr (None, None, 1, 32)  0           time_distributed_151[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_155 (TimeDistr (None, None, 1, 32)  0           time_distributed_154[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_158 (TimeDistr (None, None, 1, 32)  0           time_distributed_157[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_153 (TimeDistr (None, None, 32)     0           time_distributed_152[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_156 (TimeDistr (None, None, 32)     0           time_distributed_155[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_159 (TimeDistr (None, None, 32)     0           time_distributed_158[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_153[0][0]       \n",
      "                                                                 time_distributed_156[0][0]       \n",
      "                                                                 time_distributed_159[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional (None, None, 400)    968000      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_160 (TimeDistr (None, None, 25)     10025       bidirectional_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_20 (CRF)                    (None, None, 25)     1325        time_distributed_160[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "51/51 [==============================] - 37s 731ms/step - loss: 0.5621 - acc: 0.8849 - val_loss: 1.1966 - val_acc: 0.3064\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: 0.3136 - acc: 0.9250 - val_loss: 0.9063 - val_acc: 0.6713\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 23s 446ms/step - loss: 0.2603 - acc: 0.9338 - val_loss: 1.3125 - val_acc: 0.2734\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.2329 - acc: 0.9375 - val_loss: 1.0607 - val_acc: 0.4204\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 0.2046 - acc: 0.9421 - val_loss: 0.6244 - val_acc: 0.7713\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 26s 512ms/step - loss: 0.1853 - acc: 0.9447 - val_loss: 0.4148 - val_acc: 0.8430\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 30s 597ms/step - loss: 0.1645 - acc: 0.9472 - val_loss: 0.6472 - val_acc: 0.7095\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: 0.1445 - acc: 0.9513 - val_loss: 0.1656 - val_acc: 0.9453\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 23s 445ms/step - loss: 0.1246 - acc: 0.9580 - val_loss: 0.1286 - val_acc: 0.9590\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 25s 495ms/step - loss: 0.1262 - acc: 0.9532 - val_loss: 0.5508 - val_acc: 0.7340\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 27s 523ms/step - loss: 0.1172 - acc: 0.9578 - val_loss: 0.2549 - val_acc: 0.8906\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 23s 446ms/step - loss: 0.1015 - acc: 0.9601 - val_loss: 0.1128 - val_acc: 0.9594\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 27s 538ms/step - loss: 0.0916 - acc: 0.9608 - val_loss: 0.1201 - val_acc: 0.9498\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 24s 461ms/step - loss: 0.0823 - acc: 0.9633 - val_loss: 0.0891 - val_acc: 0.9626\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: 0.0718 - acc: 0.9646 - val_loss: 0.1413 - val_acc: 0.9546\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 23s 442ms/step - loss: 0.0685 - acc: 0.9658 - val_loss: 0.0632 - val_acc: 0.9654\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 28s 539ms/step - loss: 0.0564 - acc: 0.9672 - val_loss: 0.0565 - val_acc: 0.9667\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 23s 442ms/step - loss: 0.0502 - acc: 0.9681 - val_loss: 0.0727 - val_acc: 0.9640\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.0436 - acc: 0.9691 - val_loss: 0.0843 - val_acc: 0.9615\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 23s 455ms/step - loss: 0.0362 - acc: 0.9696 - val_loss: 0.0502 - val_acc: 0.9659\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 23s 457ms/step - loss: 0.0286 - acc: 0.9708 - val_loss: 0.0283 - val_acc: 0.9692\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 23s 443ms/step - loss: 0.0226 - acc: 0.9718 - val_loss: 0.0235 - val_acc: 0.9692\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 35s 692ms/step - loss: 0.0164 - acc: 0.9720 - val_loss: 0.0372 - val_acc: 0.9673\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 28s 552ms/step - loss: 0.0103 - acc: 0.9726 - val_loss: 0.0266 - val_acc: 0.9686\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 24s 465ms/step - loss: 0.0039 - acc: 0.9733 - val_loss: 0.0085 - val_acc: 0.9683\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 23s 444ms/step - loss: -0.0012 - acc: 0.9732 - val_loss: 0.0159 - val_acc: 0.9677\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 28s 552ms/step - loss: -0.0086 - acc: 0.9744 - val_loss: 0.0042 - val_acc: 0.9691\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.0144 - acc: 0.9750 - val_loss: 0.0011 - val_acc: 0.9696\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 23s 451ms/step - loss: -0.0164 - acc: 0.9732 - val_loss: 0.0471 - val_acc: 0.9476\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.0183 - acc: 0.9737 - val_loss: -0.0017 - val_acc: 0.9687\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.0283 - acc: 0.9756 - val_loss: -0.0246 - val_acc: 0.9713\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0347 - acc: 0.9753\n",
      "New maximum F1 score: 0.7686180804460374 (before: 0) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 31s 615ms/step - loss: -0.0342 - acc: 0.9756 - val_loss: -0.0229 - val_acc: 0.9713\n",
      "Epoch 33/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0417 - acc: 0.9765\n",
      "New maximum F1 score: 0.7703208029915372 (before: 0.7686180804460374) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 27s 529ms/step - loss: -0.0411 - acc: 0.9768 - val_loss: -0.0315 - val_acc: 0.9717\n",
      "Epoch 34/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0463 - acc: 0.9768\n",
      "New maximum F1 score: 0.7740319784241957 (before: 0.7703208029915372) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 30s 594ms/step - loss: -0.0458 - acc: 0.9772 - val_loss: -0.0402 - val_acc: 0.9717\n",
      "Epoch 35/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0519 - acc: 0.9773\n",
      "New maximum F1 score: 0.7762557077625571 (before: 0.7740319784241957) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 23s 460ms/step - loss: -0.0514 - acc: 0.9776 - val_loss: -0.0418 - val_acc: 0.9723\n",
      "Epoch 36/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0576 - acc: 0.9783 - val_loss: -0.0456 - val_acc: 0.9721\n",
      "Epoch 37/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0630 - acc: 0.9781\n",
      "New maximum F1 score: 0.78198127925117 (before: 0.7762557077625571) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 34s 669ms/step - loss: -0.0624 - acc: 0.9784 - val_loss: -0.0554 - val_acc: 0.9727\n",
      "Epoch 38/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0691 - acc: 0.9789\n",
      "New maximum F1 score: 0.7841339445883994 (before: 0.78198127925117) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 25s 491ms/step - loss: -0.0683 - acc: 0.9792 - val_loss: -0.0549 - val_acc: 0.9729\n",
      "Epoch 39/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.0738 - acc: 0.9797 - val_loss: -0.0598 - val_acc: 0.9727\n",
      "Epoch 40/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0795 - acc: 0.9795\n",
      "New maximum F1 score: 0.7863414634146342 (before: 0.7841339445883994) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 30s 597ms/step - loss: -0.0786 - acc: 0.9797 - val_loss: -0.0687 - val_acc: 0.9732\n",
      "Epoch 41/80\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.0837 - acc: 0.9798 - val_loss: -0.0503 - val_acc: 0.9699\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 24s 470ms/step - loss: -0.0877 - acc: 0.9801 - val_loss: -0.0780 - val_acc: 0.9718\n",
      "Epoch 43/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0947 - acc: 0.9800\n",
      "New maximum F1 score: 0.7870406953773211 (before: 0.7863414634146342) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 27s 528ms/step - loss: -0.0934 - acc: 0.9803 - val_loss: -0.0809 - val_acc: 0.9735\n",
      "Epoch 44/80\n",
      "51/51 [==============================] - 26s 506ms/step - loss: -0.0987 - acc: 0.9809 - val_loss: -0.0852 - val_acc: 0.9728\n",
      "Epoch 45/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1054 - acc: 0.9806\n",
      "New maximum F1 score: 0.791462698257294 (before: 0.7870406953773211) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 24s 466ms/step - loss: -0.1041 - acc: 0.9809 - val_loss: -0.0921 - val_acc: 0.9734\n",
      "Epoch 46/80\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.1093 - acc: 0.9813 - val_loss: -0.0962 - val_acc: 0.9732\n",
      "Epoch 47/80\n",
      "51/51 [==============================] - 24s 472ms/step - loss: -0.1146 - acc: 0.9818 - val_loss: -0.0986 - val_acc: 0.9730\n",
      "Epoch 48/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1205 - acc: 0.9817\n",
      "New maximum F1 score: 0.7944465869649056 (before: 0.791462698257294) Saving to tmp_generator_NER_lstm_best.4.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1190 - acc: 0.9819 - val_loss: -0.1072 - val_acc: 0.9735\n",
      "Epoch 49/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1244 - acc: 0.9821 - val_loss: -0.1135 - val_acc: 0.9728\n",
      "Epoch 50/80\n",
      "51/51 [==============================] - 35s 680ms/step - loss: -0.1292 - acc: 0.9826 - val_loss: -0.1042 - val_acc: 0.9728\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 37s 727ms/step - loss: -0.1339 - acc: 0.9825 - val_loss: -0.1183 - val_acc: 0.9737\n",
      "Epoch 52/80\n",
      "51/51 [==============================] - 25s 498ms/step - loss: -0.1394 - acc: 0.9830 - val_loss: -0.1220 - val_acc: 0.9741\n",
      "Epoch 53/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1460 - acc: 0.9832\n",
      "New maximum F1 score: 0.7960867063111452 (before: 0.7944465869649056) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 26s 508ms/step - loss: -0.1442 - acc: 0.9834 - val_loss: -0.1308 - val_acc: 0.9741\n",
      "Epoch 54/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1510 - acc: 0.9833\n",
      "New maximum F1 score: 0.8039673278879814 (before: 0.7960867063111452) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 24s 476ms/step - loss: -0.1492 - acc: 0.9835 - val_loss: -0.1357 - val_acc: 0.9750\n",
      "Epoch 55/80\n",
      "51/51 [==============================] - 28s 553ms/step - loss: -0.1543 - acc: 0.9839 - val_loss: -0.1385 - val_acc: 0.9749\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 26s 502ms/step - loss: -0.1592 - acc: 0.9841 - val_loss: -0.1419 - val_acc: 0.9743\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 26s 518ms/step - loss: -0.1634 - acc: 0.9838 - val_loss: -0.1470 - val_acc: 0.9743\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 28s 559ms/step - loss: -0.1694 - acc: 0.9851 - val_loss: -0.1516 - val_acc: 0.9748\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 24s 461ms/step - loss: -0.1734 - acc: 0.9844 - val_loss: -0.1561 - val_acc: 0.9743\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 23s 458ms/step - loss: -0.1775 - acc: 0.9847 - val_loss: -0.1585 - val_acc: 0.9740\n",
      "Epoch 61/80\n",
      "51/51 [==============================] - 28s 543ms/step - loss: -0.1828 - acc: 0.9851 - val_loss: -0.1645 - val_acc: 0.9745\n",
      "Epoch 62/80\n",
      "51/51 [==============================] - 26s 504ms/step - loss: -0.1877 - acc: 0.9853 - val_loss: -0.1721 - val_acc: 0.9742\n",
      "Epoch 63/80\n",
      "51/51 [==============================] - 24s 471ms/step - loss: -0.1920 - acc: 0.9853 - val_loss: -0.1736 - val_acc: 0.9739\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 29s 576ms/step - loss: -0.1972 - acc: 0.9855 - val_loss: -0.1748 - val_acc: 0.9736\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 28s 551ms/step - loss: -0.2016 - acc: 0.9853 - val_loss: -0.1785 - val_acc: 0.9748\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 24s 462ms/step - loss: -0.2060 - acc: 0.9857 - val_loss: -0.1814 - val_acc: 0.9742\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 24s 464ms/step - loss: -0.2107 - acc: 0.9858 - val_loss: -0.1886 - val_acc: 0.9727\n",
      "Epoch 68/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2178 - acc: 0.9857\n",
      "New maximum F1 score: 0.8052251900955351 (before: 0.8039673278879814) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 25s 484ms/step - loss: -0.2151 - acc: 0.9859 - val_loss: -0.1952 - val_acc: 0.9752\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 30s 587ms/step - loss: -0.2210 - acc: 0.9865 - val_loss: -0.1993 - val_acc: 0.9742\n",
      "Epoch 70/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2288 - acc: 0.9864\n",
      "New maximum F1 score: 0.806311637080868 (before: 0.8052251900955351) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 24s 469ms/step - loss: -0.2260 - acc: 0.9865 - val_loss: -0.2005 - val_acc: 0.9744\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 27s 531ms/step - loss: -0.2309 - acc: 0.9870 - val_loss: -0.2066 - val_acc: 0.9747\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 25s 498ms/step - loss: -0.2354 - acc: 0.9870 - val_loss: -0.2155 - val_acc: 0.9752\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 24s 467ms/step - loss: -0.2398 - acc: 0.9870 - val_loss: -0.2167 - val_acc: 0.9751\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 26s 502ms/step - loss: -0.2445 - acc: 0.9874 - val_loss: -0.2158 - val_acc: 0.9738\n",
      "Epoch 75/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2520 - acc: 0.9873\n",
      "New maximum F1 score: 0.8087389804522807 (before: 0.806311637080868) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 26s 502ms/step - loss: -0.2488 - acc: 0.9874 - val_loss: -0.2279 - val_acc: 0.9751\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 25s 499ms/step - loss: -0.2538 - acc: 0.9875 - val_loss: -0.2144 - val_acc: 0.9736\n",
      "Epoch 77/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2615 - acc: 0.9878\n",
      "New maximum F1 score: 0.8094506338839801 (before: 0.8087389804522807) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 27s 521ms/step - loss: -0.2582 - acc: 0.9879 - val_loss: -0.2366 - val_acc: 0.9753\n",
      "Epoch 78/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2661 - acc: 0.9874\n",
      "New maximum F1 score: 0.8126577363618714 (before: 0.8094506338839801) Saving to tmp_generator_NER_lstm_best.4.h5\n",
      "51/51 [==============================] - 25s 497ms/step - loss: -0.2628 - acc: 0.9876 - val_loss: -0.2414 - val_acc: 0.9755\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 26s 512ms/step - loss: -0.2674 - acc: 0.9879 - val_loss: -0.2442 - val_acc: 0.9739\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 26s 509ms/step - loss: -0.2718 - acc: 0.9881 - val_loss: -0.2486 - val_acc: 0.9746\n",
      "Run 5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_161 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_164 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_167 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_162 (TimeDistr (None, None, 1, 32)  0           time_distributed_161[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_165 (TimeDistr (None, None, 1, 32)  0           time_distributed_164[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_168 (TimeDistr (None, None, 1, 32)  0           time_distributed_167[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_163 (TimeDistr (None, None, 32)     0           time_distributed_162[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_166 (TimeDistr (None, None, 32)     0           time_distributed_165[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_169 (TimeDistr (None, None, 32)     0           time_distributed_168[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_163[0][0]       \n",
      "                                                                 time_distributed_166[0][0]       \n",
      "                                                                 time_distributed_169[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_32 (Bidirectional (None, None, 400)    968000      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_170 (TimeDistr (None, None, 25)     10025       bidirectional_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_21 (CRF)                    (None, None, 25)     1325        time_distributed_170[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "51/51 [==============================] - 48s 950ms/step - loss: 0.5989 - acc: 0.8822 - val_loss: 1.5309 - val_acc: 0.3256\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 29s 565ms/step - loss: 0.3248 - acc: 0.9221 - val_loss: 0.7904 - val_acc: 0.8009\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 26s 508ms/step - loss: 0.2565 - acc: 0.9352 - val_loss: 0.9733 - val_acc: 0.5600\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 25s 495ms/step - loss: 0.2500 - acc: 0.9309 - val_loss: 0.3830 - val_acc: 0.9363\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 36s 713ms/step - loss: 0.2032 - acc: 0.9428 - val_loss: 0.5214 - val_acc: 0.8422\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 30s 586ms/step - loss: 0.1756 - acc: 0.9472 - val_loss: 0.3797 - val_acc: 0.8777\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 27s 532ms/step - loss: 0.1593 - acc: 0.9503 - val_loss: 0.3562 - val_acc: 0.8683\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 30s 590ms/step - loss: 0.1399 - acc: 0.9543 - val_loss: 0.1255 - val_acc: 0.9585\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 32s 619ms/step - loss: 0.1296 - acc: 0.9534 - val_loss: 1.0392 - val_acc: 0.4787\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 31s 608ms/step - loss: 0.1221 - acc: 0.9563 - val_loss: 0.1687 - val_acc: 0.9516\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 30s 588ms/step - loss: 0.1110 - acc: 0.9569 - val_loss: 0.3315 - val_acc: 0.8482\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 45s 877ms/step - loss: 0.0996 - acc: 0.9608 - val_loss: 0.1557 - val_acc: 0.9537\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 37s 733ms/step - loss: 0.0938 - acc: 0.9591 - val_loss: 0.2905 - val_acc: 0.8666\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 36s 714ms/step - loss: 0.0876 - acc: 0.9609 - val_loss: 0.1453 - val_acc: 0.9550\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 37s 723ms/step - loss: 0.0839 - acc: 0.9622 - val_loss: 0.2171 - val_acc: 0.8972\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 32s 633ms/step - loss: 0.0711 - acc: 0.9645 - val_loss: 0.1209 - val_acc: 0.9568\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 40s 793ms/step - loss: 0.0653 - acc: 0.9645 - val_loss: 0.0840 - val_acc: 0.9546\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 39s 757ms/step - loss: 0.0557 - acc: 0.9656 - val_loss: 0.1131 - val_acc: 0.9571\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 41s 803ms/step - loss: 0.0506 - acc: 0.9684 - val_loss: 0.0505 - val_acc: 0.9662\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 28s 544ms/step - loss: 0.0388 - acc: 0.9684 - val_loss: 0.0381 - val_acc: 0.9666\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 28s 546ms/step - loss: 0.0312 - acc: 0.9700 - val_loss: 0.0605 - val_acc: 0.9639\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 28s 544ms/step - loss: 0.0250 - acc: 0.9707 - val_loss: 0.0275 - val_acc: 0.9685\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 37s 719ms/step - loss: 0.0172 - acc: 0.9717 - val_loss: 0.0223 - val_acc: 0.9681\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 24s 477ms/step - loss: 0.0103 - acc: 0.9727 - val_loss: 0.0152 - val_acc: 0.9694\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 24s 473ms/step - loss: 0.0039 - acc: 0.9733 - val_loss: 0.0218 - val_acc: 0.9663\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 33s 641ms/step - loss: -8.1333e-04 - acc: 0.9735 - val_loss: 0.0038 - val_acc: 0.9701\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 33s 656ms/step - loss: -0.0059 - acc: 0.9735 - val_loss: -0.0050 - val_acc: 0.9700\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 31s 601ms/step - loss: -0.0108 - acc: 0.9731 - val_loss: 0.0218 - val_acc: 0.9673\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 25s 487ms/step - loss: -0.0163 - acc: 0.9748 - val_loss: -0.0125 - val_acc: 0.9707\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 31s 618ms/step - loss: -0.0229 - acc: 0.9751 - val_loss: -0.0174 - val_acc: 0.9710\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 37s 734ms/step - loss: -0.0291 - acc: 0.9759 - val_loss: -0.0219 - val_acc: 0.9712\n",
      "Epoch 32/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0343 - acc: 0.9758\n",
      "New maximum F1 score: 0.7694759912333133 (before: 0) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 38s 752ms/step - loss: -0.0340 - acc: 0.9762 - val_loss: -0.0264 - val_acc: 0.9713\n",
      "Epoch 33/80\n",
      "51/51 [==============================] - 25s 488ms/step - loss: -0.0404 - acc: 0.9767 - val_loss: -0.0221 - val_acc: 0.9704\n",
      "Epoch 34/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0457 - acc: 0.9767\n",
      "New maximum F1 score: 0.774104137794496 (before: 0.7694759912333133) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 35s 696ms/step - loss: -0.0451 - acc: 0.9770 - val_loss: -0.0377 - val_acc: 0.9721\n",
      "Epoch 35/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0516 - acc: 0.9770\n",
      "New maximum F1 score: 0.7753233830845772 (before: 0.774104137794496) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 35s 691ms/step - loss: -0.0510 - acc: 0.9773 - val_loss: -0.0400 - val_acc: 0.9721\n",
      "Epoch 36/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0575 - acc: 0.9779\n",
      "New maximum F1 score: 0.779869229245096 (before: 0.7753233830845772) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 25s 498ms/step - loss: -0.0568 - acc: 0.9782 - val_loss: -0.0476 - val_acc: 0.9722\n",
      "Epoch 37/80\n",
      "51/51 [==============================] - 24s 473ms/step - loss: -0.0623 - acc: 0.9786 - val_loss: -0.0538 - val_acc: 0.9717\n",
      "Epoch 38/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0681 - acc: 0.9788\n",
      "New maximum F1 score: 0.7842299475626336 (before: 0.779869229245096) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 30s 587ms/step - loss: -0.0673 - acc: 0.9791 - val_loss: -0.0595 - val_acc: 0.9729\n",
      "Epoch 39/80\n",
      "51/51 [==============================] - 31s 614ms/step - loss: -0.0726 - acc: 0.9792 - val_loss: -0.0597 - val_acc: 0.9717\n",
      "Epoch 40/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.0778 - acc: 0.9797 - val_loss: -0.0675 - val_acc: 0.9728\n",
      "Epoch 41/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0845 - acc: 0.9797\n",
      "New maximum F1 score: 0.7856860419137999 (before: 0.7842299475626336) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 508ms/step - loss: -0.0834 - acc: 0.9800 - val_loss: -0.0699 - val_acc: 0.9730\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 34s 675ms/step - loss: -0.0880 - acc: 0.9803 - val_loss: -0.0762 - val_acc: 0.9706\n",
      "Epoch 43/80\n",
      "51/51 [==============================] - 30s 585ms/step - loss: -0.0908 - acc: 0.9795 - val_loss: -0.0485 - val_acc: 0.9694\n",
      "Epoch 44/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.0964 - acc: 0.9798\n",
      "New maximum F1 score: 0.7916666666666667 (before: 0.7856860419137999) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 501ms/step - loss: -0.0950 - acc: 0.9801 - val_loss: -0.0857 - val_acc: 0.9731\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 28s 550ms/step - loss: -0.1023 - acc: 0.9811 - val_loss: -0.0884 - val_acc: 0.9727\n",
      "Epoch 46/80\n",
      "51/51 [==============================] - 29s 578ms/step - loss: -0.1074 - acc: 0.9811 - val_loss: -0.0977 - val_acc: 0.9727\n",
      "Epoch 47/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1143 - acc: 0.9811\n",
      "New maximum F1 score: 0.7920792079207921 (before: 0.7916666666666667) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 25s 492ms/step - loss: -0.1129 - acc: 0.9813 - val_loss: -0.0993 - val_acc: 0.9734\n",
      "Epoch 48/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1194 - acc: 0.9819\n",
      "New maximum F1 score: 0.7925262748151032 (before: 0.7920792079207921) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 502ms/step - loss: -0.1180 - acc: 0.9821 - val_loss: -0.1051 - val_acc: 0.9738\n",
      "Epoch 49/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/51 [============================>.] - ETA: 0s - loss: -0.1246 - acc: 0.9823\n",
      "New maximum F1 score: 0.793854531310774 (before: 0.7925262748151032) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 36s 713ms/step - loss: -0.1231 - acc: 0.9826 - val_loss: -0.1112 - val_acc: 0.9733\n",
      "Epoch 50/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1293 - acc: 0.9822\n",
      "New maximum F1 score: 0.7964809384164224 (before: 0.793854531310774) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 31s 609ms/step - loss: -0.1277 - acc: 0.9824 - val_loss: -0.1131 - val_acc: 0.9743\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 24s 468ms/step - loss: -0.1336 - acc: 0.9828 - val_loss: -0.1198 - val_acc: 0.9735\n",
      "Epoch 52/80\n",
      "51/51 [==============================] - 29s 566ms/step - loss: -0.1377 - acc: 0.9828 - val_loss: -0.1191 - val_acc: 0.9736\n",
      "Epoch 53/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1445 - acc: 0.9829\n",
      "New maximum F1 score: 0.7984600577478345 (before: 0.7964809384164224) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 519ms/step - loss: -0.1427 - acc: 0.9831 - val_loss: -0.1314 - val_acc: 0.9741\n",
      "Epoch 54/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.1478 - acc: 0.9838 - val_loss: -0.1310 - val_acc: 0.9739\n",
      "Epoch 55/80\n",
      "51/51 [==============================] - 24s 479ms/step - loss: -0.1527 - acc: 0.9837 - val_loss: -0.1353 - val_acc: 0.9732\n",
      "Epoch 56/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1591 - acc: 0.9837\n",
      "New maximum F1 score: 0.8001556723097879 (before: 0.7984600577478345) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 37s 718ms/step - loss: -0.1571 - acc: 0.9839 - val_loss: -0.1414 - val_acc: 0.9745\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 28s 542ms/step - loss: -0.1619 - acc: 0.9837 - val_loss: -0.1431 - val_acc: 0.9744\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: -0.1673 - acc: 0.9843 - val_loss: -0.1508 - val_acc: 0.9745\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 34s 671ms/step - loss: -0.1723 - acc: 0.9845 - val_loss: -0.1534 - val_acc: 0.9743\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 38s 755ms/step - loss: -0.1768 - acc: 0.9847 - val_loss: -0.1567 - val_acc: 0.9745\n",
      "Epoch 61/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1835 - acc: 0.9848\n",
      "New maximum F1 score: 0.803356856761396 (before: 0.8001556723097879) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 508ms/step - loss: -0.1812 - acc: 0.9850 - val_loss: -0.1661 - val_acc: 0.9748\n",
      "Epoch 62/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1888 - acc: 0.9850\n",
      "New maximum F1 score: 0.8088436705145764 (before: 0.803356856761396) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 25s 483ms/step - loss: -0.1864 - acc: 0.9851 - val_loss: -0.1673 - val_acc: 0.9752\n",
      "Epoch 63/80\n",
      "51/51 [==============================] - 31s 602ms/step - loss: -0.1916 - acc: 0.9854 - val_loss: -0.1729 - val_acc: 0.9754\n",
      "Epoch 64/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.1991 - acc: 0.9858\n",
      "New maximum F1 score: 0.8105385509492445 (before: 0.8088436705145764) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 26s 509ms/step - loss: -0.1966 - acc: 0.9859 - val_loss: -0.1796 - val_acc: 0.9755\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 24s 475ms/step - loss: -0.2012 - acc: 0.9860 - val_loss: -0.1803 - val_acc: 0.9746\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 34s 657ms/step - loss: -0.2056 - acc: 0.9862 - val_loss: -0.1835 - val_acc: 0.9740\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 37s 721ms/step - loss: -0.2104 - acc: 0.9863 - val_loss: -0.1920 - val_acc: 0.9740\n",
      "Epoch 68/80\n",
      "51/51 [==============================] - 25s 498ms/step - loss: -0.2148 - acc: 0.9865 - val_loss: -0.1932 - val_acc: 0.9744\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 26s 518ms/step - loss: -0.2191 - acc: 0.9862 - val_loss: -0.1914 - val_acc: 0.9744\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 33s 657ms/step - loss: -0.2233 - acc: 0.9863 - val_loss: -0.2031 - val_acc: 0.9756\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 25s 489ms/step - loss: -0.2289 - acc: 0.9867 - val_loss: -0.2039 - val_acc: 0.9740\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 25s 493ms/step - loss: -0.2330 - acc: 0.9868 - val_loss: -0.2128 - val_acc: 0.9751\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 29s 575ms/step - loss: -0.2381 - acc: 0.9871 - val_loss: -0.2166 - val_acc: 0.9745\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 29s 577ms/step - loss: -0.2428 - acc: 0.9874 - val_loss: -0.2234 - val_acc: 0.9741\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 29s 568ms/step - loss: -0.2473 - acc: 0.9874 - val_loss: -0.2251 - val_acc: 0.9754\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 26s 501ms/step - loss: -0.2526 - acc: 0.9881 - val_loss: -0.2295 - val_acc: 0.9755\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 33s 637ms/step - loss: -0.2570 - acc: 0.9877 - val_loss: -0.2345 - val_acc: 0.9752\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 31s 600ms/step - loss: -0.2620 - acc: 0.9879 - val_loss: -0.2356 - val_acc: 0.9753\n",
      "Epoch 79/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: -0.2691 - acc: 0.9876\n",
      "New maximum F1 score: 0.8111993946273175 (before: 0.8105385509492445) Saving to tmp_generator_NER_lstm_best.5.h5\n",
      "51/51 [==============================] - 25s 483ms/step - loss: -0.2656 - acc: 0.9877 - val_loss: -0.2461 - val_acc: 0.9755\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 25s 494ms/step - loss: -0.2706 - acc: 0.9881 - val_loss: -0.2441 - val_acc: 0.9746\n",
      "Run 6\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 100, 32 10528       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_171 (TimeDistr (None, None, 100, 32 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_174 (TimeDistr (None, None, 100, 32 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_177 (TimeDistr (None, None, 100, 32 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_172 (TimeDistr (None, None, 1, 32)  0           time_distributed_171[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_175 (TimeDistr (None, None, 1, 32)  0           time_distributed_174[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_178 (TimeDistr (None, None, 1, 32)  0           time_distributed_177[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_173 (TimeDistr (None, None, 32)     0           time_distributed_172[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_176 (TimeDistr (None, None, 32)     0           time_distributed_175[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_179 (TimeDistr (None, None, 32)     0           time_distributed_178[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_173[0][0]       \n",
      "                                                                 time_distributed_176[0][0]       \n",
      "                                                                 time_distributed_179[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_33 (Bidirectional (None, None, 400)    968000      concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_180 (TimeDistr (None, None, 25)     10025       bidirectional_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf_22 (CRF)                    (None, None, 25)     1325        time_distributed_180[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,002,326\n",
      "Trainable params: 1,002,262\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "51/51 [==============================] - 44s 859ms/step - loss: 0.5944 - acc: 0.8808 - val_loss: 0.9106 - val_acc: 0.7010\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 30s 594ms/step - loss: 0.3208 - acc: 0.9223 - val_loss: 1.1161 - val_acc: 0.6027\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 25s 491ms/step - loss: 0.2659 - acc: 0.9353 - val_loss: 1.0630 - val_acc: 0.5161\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 25s 494ms/step - loss: 0.2285 - acc: 0.9378 - val_loss: 0.9693 - val_acc: 0.5677\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 29s 563ms/step - loss: 0.2132 - acc: 0.9402 - val_loss: 0.7053 - val_acc: 0.7612\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 25s 486ms/step - loss: 0.1824 - acc: 0.9473 - val_loss: 0.3152 - val_acc: 0.9131\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 24s 480ms/step - loss: 0.1566 - acc: 0.9527 - val_loss: 0.3141 - val_acc: 0.8967\n",
      "Epoch 8/80\n",
      "51/51 [==============================] - 25s 482ms/step - loss: 0.1407 - acc: 0.9557 - val_loss: 0.1222 - val_acc: 0.9588\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 25s 489ms/step - loss: 0.1312 - acc: 0.9532 - val_loss: 0.6780 - val_acc: 0.7138\n",
      "Epoch 10/80\n",
      "50/51 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9564"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-73205b464c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2211\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2213\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2214\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-5c974abe2717>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2Label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-38911d1bdfd4>\u001b[0m in \u001b[0;36mpredict_batches\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpred_labels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_labels_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mpred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_label_from_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_label_from_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-38911d1bdfd4>\u001b[0m in \u001b[0;36mget_label_from_categorical\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kerasenv/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f = open('results_lstm.txt', 'w')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'tmp_generator_NER_lstm_best.' + str(run_i) + '.h5'\n",
    "    # tmp_model_filename = 'tmp_generator_NER_best.h5'\n",
    "    # checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "    history = F1History()\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit_generator(\n",
    "        generator(train_batches), \n",
    "        epochs = 80, steps_per_epoch = len(train_batches), \n",
    "        validation_data = generator(dev_batches), validation_steps = len(dev_batches), \n",
    "        callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    true_labels, pred_labels = predict_batches(test_batches)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_generator_NER_best.0.h5', 'final_model_germeval.h5')\n",
    "with open(\"final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([idx2Label, label2Idx, char2Idx, case2Idx], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
